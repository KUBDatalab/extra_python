{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RegEx og Frankenstein"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Online RegEx tester, [regex101](https://regex101.com/), is a helpful site for learning how to use regular expressions (Regex).\n",
    "\n",
    "[W3schools](https://www.w3schools.com/python/python_regex.asp) also has a very useful page about RegEx.\n",
    "\n",
    "Regex's use is very widespread because RegEx is super smart in relation to text processing, because it can be used to perform advanced searches. RegEx is used for search engines and for search and replace functions. Working with RegEx is definitely an experience in itself, but when you get an insight into the scope of tasks that can be solved with RegEx, you realize that it is an incredibly good tool.\n",
    "\n",
    "This notebook doesn't try to teach you everything about RegEx, but it does try to create learning about it, and only a few of the possibilities are illustrated below.\n",
    "\n",
    "In addition to RegEx, this notebook contains many loops and list comprehensions, so that way you can also get an insight into how to write this sort of thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request \n",
    "url = 'https://gutenberg.org/cache/epub/84/pg84.txt'\n",
    "raw_text = urllib.request.urlopen(url).read().decode()\n",
    "text_start = raw_text.find('*** START OF THE PROJECT GUTENBERG EBOOK FRANKENSTEIN; OR, THE MODERN PROMETHEUS ***')\n",
    "text_start = text_start + len('*** START OF THE PROJECT GUTENBERG EBOOK FRANKENSTEIN; OR, THE MODERN PROMETHEUS ***')\n",
    "text_end = raw_text.find('*** END OF THE PROJECT GUTENBERG EBOOK FRANKENSTEIN; OR, THE MODERN PROMETHEUS ***')\n",
    "text = raw_text[text_start:text_end].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text[0:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta characters \\b \\S og \\w and the + sign\n",
    "\n",
    "We often need to clean the texts of symbols such as commas and full stops, etc.\n",
    "\n",
    "Cleaning of text can be done in several ways. Below we try out a few of the ways. We begin by importing RegEx (import re)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First way\n",
    "The RegEx pattern is '\\b\\S+\\b'.\n",
    "\n",
    "\\b : \\b finds the position at the boundary of a word (word boundary).\n",
    "\\S: \\S matches any non-space\n",
    "+: + matches the previous character between one and an unlimited number of times, as many times as possible until the next character. They say the plus is greedy.\n",
    "\\b : \\b finds the position at the boundary of a word (word boundary).\n",
    "\n",
    "When you set \\b\\S+\\b, you match from, you match all \"non-space characters\" as well as underscores, but not symbols such as periods, commas, question marks.\n",
    "\n",
    "\n",
    "## Second way\n",
    "\\w: \\w matches any alphabetic letter (uppercase and lowercase), any number, or an underscore (_).\n",
    "+: + matches the preceding character one or more times.\n",
    "\n",
    "When you put \\w+ together, you match whole words composed of letters, digits and underscores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_1(text):\n",
    "    # Use \\w+ regex pattern to extract words\n",
    "    words = re.findall(r'\\b\\S+\\b', text)\n",
    "\n",
    "    # Join the extracted words into a cleaned text\n",
    "    cleaned_text = ' '.join(words)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "\n",
    "def clean_text_2(text):\n",
    "    # Use \\w+ regex pattern to extract words\n",
    "    words = re.findall(r'\\w+', text)\n",
    "\n",
    "    # Join the extracted words into a cleaned text\n",
    "    cleaned_text = ' '.join(words)\n",
    "\n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = clean_text_1(text)\n",
    "\n",
    "print(cleaned_text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_text = clean_text_2(text)\n",
    "\n",
    "print(cleaned_text[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must try to relate to the results and compare the results.\n",
    "\n",
    "Search e.g. after Thereâ€”for\n",
    "In the first method, the There-for remains in a word. In the second method, it becomes two words.\n",
    "\n",
    "Search e.g. after About two o'clock.\n",
    "\n",
    "In the first method, o'clock remains a word. In the second method, it becomes two words \"o clock\".\n",
    "\n",
    "Both methods leave us with underscores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# w+ along with \\b\n",
    "\n",
    "Why doesn't anything happen on a Friday?\n",
    "\n",
    "Find words with special endings, e.g. _day_, can be a help to gain insight into where and when the literature takes place.\n",
    "\n",
    "You can also use the endings to find grammatical forms, e.g. words with a long affix will be relatively easy to identify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ending = re.findall(r'\\w+day\\b', text)\n",
    "print(ending)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More metacharacters, as well as pipes, lists and question marks\n",
    "\n",
    "In literature, comparisons are often used to illustrate points more clearly by putting pictures on what you want to describe. Comparisons also contribute to making the text more lively and interesting.\n",
    "\n",
    "But regex makes it a manageable task to retrieve examples of comparisons, because we can find text strings that follow the pattern of a typical comparison.\n",
    "\n",
    "We can illustrate it in the following way. We look for phrases whose pattern is either as a ... or as an ....\n",
    "\n",
    "The RegEx pattern can be written like this:\n",
    "\n",
    "'as\\sa\\s\\w+'\n",
    "\n",
    "The word 'as' is followed by \\s, meaning white space, followed by a, then followed by \\s, followed by \\w, meaning word charater, followed by + meaning \"one or more of the previous\".\n",
    "\n",
    "\n",
    "If you also want to search for \"as an ...\" there are two ways to do it.\n",
    "\n",
    "\n",
    "First way is to use pipe |. Pipe means \"or\". The regex pattern will then look like this: 'as\\sa\\s\\w+|as\\san\\s\\w+'\n",
    "\n",
    "Another way is to use the list character []?\n",
    "\n",
    "It looks like this: 'as\\sa[n]?\\s\\w+'. In the list, letters can be added that can stand in that place in the word. The question mark indicates that the letter may or may not be there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = re.findall(r'as\\sa\\s\\w+', cleaned_text)\n",
    "print (comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = re.findall(r'as\\sa\\s\\w+|as\\san\\s\\w+', cleaned_text)\n",
    "print (comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison = re.findall(r'as\\sa[n]?\\s\\w+', cleaned_text)\n",
    "print (comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curly brackets\n",
    "\n",
    "Keyword-in-context, contexts or find a text snippet based on keywords and a range.\n",
    "\n",
    "We want to find text extracts that contain Turk or Roman, because we are actually interested in pointing down in the text and seeing how exactly the terms are used.\n",
    "\n",
    "For this we need to use the full stop ( . ) because it gives us more word characters and {30} searches for us to get 30 word characters before we hit the letters Turk.\n",
    "\n",
    "The period {30} after Turk gives us another 30 word characters.\n",
    "\n",
    "Try to see if you can use some of what has been reviewed above to include text extracts that contain the word Roman."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re.findall(r'.{30}Turk.{30}', cleaned_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Square brackets [A-Z]\n",
    "\n",
    "Find words that start with capital letters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper_case_word = re.findall(r'[A-Z]\\w+', text)\n",
    "print (upper_case_word[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of these words are capitalized because they appear after a period, and thus are not what I would call \"real\" capitalized words.\n",
    "\n",
    "If you want to filter out the \"inauthentic\" words from your list, then you can reveal them by making a loop and inserting a condition that can check whether the words should be written in lowercase elsewhere in the texts, because if they are, then they are \"fake\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_upper_case = []\n",
    "for word in upper_case_word:\n",
    "    if word.lower() not in text:\n",
    "        true_upper_case.append(word)\n",
    "print (true_upper_case[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
